<br />
<div align="center">
  <h3 align="center">Basit Otonom SÃ¼rÃ¼ÅŸ: Engelden KaÃ§ma / Duvar Ä°zleme</h3>

  <p align="center">
    ROS ve Lidar SensÃ¶rÃ¼ Kullanarak FSM TabanlÄ± Otonom Navigasyon
    <br />
    <br />
  </p>
</div>

<div align="center">
  <img src="https://img.shields.io/badge/ROS-Melodic%2FNoetic-22314E?style=for-the-badge&logo=ros&logoColor=white" alt="ROS">
  <img src="https://img.shields.io/badge/Python-3.x-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/Ubuntu-20.04-E95420?style=for-the-badge&logo=ubuntu&logoColor=white" alt="Ubuntu">
</div>

<br/>

<details>
  <summary>ğŸ“ Ä°Ã§indekiler (TR)</summary>
  <ol>
    <li>
      <a href="#proje-hakkÄ±nda">Proje HakkÄ±nda</a>
      <ul>
        <li><a href="#fsm-yapÄ±sÄ±">FSM YapÄ±sÄ±</a></li>
        <li><a href="#kullanÄ±lan-topicler">KullanÄ±lan Topic'ler</a></li>
      </ul>
    </li>
    <li>
      <a href="#kurulum-ve-Ã§alÄ±ÅŸtÄ±rma">Kurulum ve Ã‡alÄ±ÅŸtÄ±rma</a>
    </li>
    <li><a href="#kullanÄ±lan-parametreler">KullanÄ±lan Parametreler</a></li>
  </ol>
</details>

---

## Proje HakkÄ±nda

Bu proje, bir mobil robotun (TurtleBot) kapalÄ± bir parkurda engellere Ã§arpmadan ilerlemesini saÄŸlayan otonom bir ROS dÃ¼ÄŸÃ¼mÃ¼ (node) iÃ§erir. 

Proje, **Sonlu Durum Makinesi (Finite State Machine - FSM)** mimarisi Ã¼zerine kurulmuÅŸtur. Robot, LIDAR sensÃ¶rÃ¼nden (`/scan`) gelen verileri iÅŸleyerek Ã§evresindeki engelleri algÄ±lar ve duruma gÃ¶re hareket kararÄ± verir.

### FSM YapÄ±sÄ±

Robotun davranÄ±ÅŸ mantÄ±ÄŸÄ± aÅŸaÄŸÄ±daki durum diyagramÄ±nda gÃ¶sterilmiÅŸtir:

```mermaid
graph LR
    A((BAÅLANGIÃ‡)) --> B{Mesafe KontrolÃ¼}
    B -- "Yol AÃ§Ä±k" --> C[Ä°LERÄ° SÃœR]
    B -- "Engel Var (< 1.0m)" --> D[DÃ–NÃœÅ YAP]
    B -- "Kritik Mesafe (< 0.7m)" --> E["KAÃ‡INMA (Geri Git)"]
    D -- "Engel Devam Ediyor" --> D
    D -- "Yol AÃ§Ä±ldÄ±" --> C
    E -- "GÃ¼venli Mesafeye Ã‡Ä±ktÄ±" --> C
```

### KullanÄ±lan Topic'ler

Robotun sensÃ¶r verilerini okumak ve hareket komutlarÄ± gÃ¶ndermek iÃ§in kullandÄ±ÄŸÄ± ROS topicleri ÅŸunlardÄ±r:

| Topic AdÄ± | Mesaj Tipi | AÃ§Ä±klama |
| :--- | :--- | :--- |
| `/scan` | `sensor_msgs/LaserScan` | Lidar sensÃ¶rÃ¼nden gelen mesafe verileri |
| `/mobile_base/commands/velocity` | `geometry_msgs/Twist` | Robota gÃ¶nderilen hÄ±z komutlarÄ± |
| `~state` | `std_msgs/String` | Debug amaÃ§lÄ± anlÄ±k FSM durumu yayÄ±nÄ± |

---

## Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

Bu projeyi yerel ortamÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin.

### 1. Gereksinimler
* ROS (Melodic veya Noetic)
* Python 3
* `geometry_msgs`, `sensor_msgs` paketleri

### 2. Ä°ndirme ve Derleme

```bash
cd ~/catkin_ws/src
git clone [https://github.com/AlperenER/simple_autonomous_driving.git](https://github.com/AlperenER/simple_autonomous_driving.git)
cd ..
catkin_make
source devel/setup.bash
```

### 3. SimÃ¼lasyonu veya Robotu BaÅŸlatma

Ã–nce robotun temel sÃ¼rÃ¼cÃ¼lerini ve lidar sensÃ¶rÃ¼nÃ¼ baÅŸlatÄ±n:

```bash
roslaunch turtlebot_bringup minimal.launch
roslaunch rplidar_ros test_rplidar.launch
```

### 4. Otonom DÃ¼ÄŸÃ¼mÃ¼ Ã‡alÄ±ÅŸtÄ±rma

GÃ¶revi baÅŸlatmak iÃ§in oluÅŸturulan Python scriptini Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
rosrun simple_autonomous_driving gorev1_fsm_node.py
```

---

## KullanÄ±lan Parametreler

Robotun davranÄ±ÅŸÄ±nÄ± deÄŸiÅŸtirmek iÃ§in kod iÃ§erisindeki aÅŸaÄŸÄ±daki deÄŸiÅŸkenler dÃ¼zenlenebilir:

| DeÄŸiÅŸken | DeÄŸer | AÃ§Ä±klama |
| :--- | :--- | :--- |
| `forward_speed` | 0.15 | Robotun dÃ¼z sÃ¼rÃ¼ÅŸ hÄ±zÄ± (m/s) |
| `turn_speed` | 0.45 | DÃ¶nÃ¼ÅŸ hÄ±zÄ± (rad/s) |
| `obstacle_dist` | 1.0 | Engel algÄ±lama mesafesi (metre) |
| `critical_dist` | 0.7 | Acil durum kaÃ§Ä±nma mesafesi (metre) |
| `blind_spot` | 0.15 | SensÃ¶r kÃ¶r nokta filtresi |

---

<div align="center">
  <p><b>Alperen ER</b></p>
  <p>
    <a href="https://github.com/AlperenER">
      <img src="https://img.shields.io/badge/GitHub-Profilim-black?style=flat-square&logo=github" alt="GitHub">
    </a>
  </p>
</div>

<br />
<br />
<br />

---
<div align="center">
  <h1>ğŸ‡¬ğŸ‡§ English Description</h1>
</div>
---

<div align="center">
  <h3 align="center">Simple Autonomous Driving: Obstacle Avoidance / Wall Following</h3>

  <p align="center">
    FSM Based Autonomous Navigation Using ROS and Lidar Sensor
    <br />
    <br />
  </p>
</div>

<details>
  <summary>ğŸ“ Table of Contents (EN)</summary>
  <ol>
    <li>
      <a href="#about-the-project">About the Project</a>
      <ul>
        <li><a href="#fsm-structure">FSM Structure</a></li>
        <li><a href="#topics-used">Topics Used</a></li>
      </ul>
    </li>
    <li>
      <a href="#installation-and-execution">Installation and Execution</a>
    </li>
    <li><a href="#parameters-used">Parameters Used</a></li>
  </ol>
</details>

---

## About the Project

This project contains an autonomous ROS node that enables a mobile robot (TurtleBot) to move in a closed course without hitting obstacles.

The project is built on the **Finite State Machine (FSM)** architecture. The robot processes data from the LIDAR sensor (`/scan`) to detect surrounding obstacles and decides on movement accordingly.

### FSM Structure

The logic of the robot's behavior is shown in the state diagram below:

```mermaid
graph LR
    A((START)) --> B{Distance Check}
    B -- "Path Clear" --> C[DRIVE FORWARD]
    B -- "Obstacle Detected (< 1.0m)" --> D[TURN]
    B -- "Critical Distance (< 0.7m)" --> E["AVOID (Move Back)"]
    D -- "Obstacle Persists" --> D
    D -- "Path Cleared" --> C
    E -- "Safe Distance Reached" --> C
```

### Topics Used

The ROS topics used by the robot to read sensor data and send motion commands are as follows:

| Topic Name | Message Type | Description |
| :--- | :--- | :--- |
| `/scan` | `sensor_msgs/LaserScan` | Distance data from Lidar sensor |
| `/mobile_base/commands/velocity` | `geometry_msgs/Twist` | Velocity commands sent to the robot |
| `~state` | `std_msgs/String` | Instant FSM state publishing for debugging |

---

## Installation and Execution

Follow the steps below to run this project in your local environment.

### 1. Requirements
* ROS (Melodic or Noetic)
* Python 3
* `geometry_msgs`, `sensor_msgs` packages

### 2. Download and Compile

```bash
cd ~/catkin_ws/src
git clone [https://github.com/AlperenER/simple_autonomous_driving.git](https://github.com/AlperenER/simple_autonomous_driving.git)
cd ..
catkin_make
source devel/setup.bash
```

### 3. Starting Simulation or Robot

First, start the robot's basic drivers and lidar sensor:

```bash
roslaunch turtlebot_bringup minimal.launch
roslaunch rplidar_ros test_rplidar.launch
```

### 4. Running the Autonomous Node

Run the created Python script to start the task:

```bash
rosrun simple_autonomous_driving gorev1_fsm_node.py
```

---

## Parameters Used

The following variables in the code can be edited to change the robot's behavior:

| Variable | Value | Description |
| :--- | :--- | :--- |
| `forward_speed` | 0.15 | Robot forward driving speed (m/s) |
| `turn_speed` | 0.45 | Turning speed (rad/s) |
| `obstacle_dist` | 1.0 | Obstacle detection distance (meter) |
| `critical_dist` | 0.7 | Emergency avoidance distance (meter) |
| `blind_spot` | 0.15 | Sensor blind spot filter |

---

<div align="center">
  <p><b>Alperen ER</b></p>
  <p>
    <a href="https://github.com/AlperenER">
      <img src="https://img.shields.io/badge/GitHub-My%20Profile-black?style=flat-square&logo=github" alt="GitHub">
    </a>
  </p>
</div>
```
